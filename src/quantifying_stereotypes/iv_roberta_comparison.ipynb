{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f57dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070 Ti SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d19f0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lauyon/quantifying-stereotype-roberta\", device_map=\"cuda\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"lauyon/quantifying-stereotype-roberta\", device_map=\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45403663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90644248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(text, pad, max_len=50):\n",
    "    return text if len(text) >= max_len else (text + [pad] * (max_len - len(text)))\n",
    "\n",
    "\n",
    "def encode_batch(text, berts, max_len=50):\n",
    "    tokenizer = berts[0]\n",
    "    t1 = []\n",
    "    for line in text:\n",
    "        t1.append(padding(tokenizer.encode(line, add_special_tokens=True, max_length=max_len, truncation=True),\n",
    "                          tokenizer.pad_token_id, max_len))\n",
    "    return t1\n",
    "\n",
    "\n",
    "def data_iterator(train_y, batch_size=64):\n",
    "    n_batches = math.ceil(len(train_y) / batch_size)\n",
    "    for idx in range(n_batches):\n",
    "        y = train_y[idx * batch_size:(idx + 1) * batch_size]\n",
    "        yield y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "014e58de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/3953\n",
      "512/3953\n",
      "768/3953\n",
      "1024/3953\n",
      "1280/3953\n",
      "1536/3953\n",
      "1792/3953\n",
      "2048/3953\n",
      "2304/3953\n",
      "2560/3953\n",
      "2816/3953\n",
      "3072/3953\n",
      "3328/3953\n",
      "3584/3953\n",
      "3840/3953\n",
      "4096/3953\n",
      "4352/3953\n",
      "4608/3953\n",
      "4864/3953\n",
      "5120/3953\n",
      "5376/3953\n",
      "5632/3953\n",
      "5888/3953\n",
      "6144/3953\n",
      "6400/3953\n",
      "6656/3953\n",
      "6912/3953\n",
      "7168/3953\n",
      "7424/3953\n",
      "7680/3953\n",
      "7936/3953\n",
      "8192/3953\n",
      "8448/3953\n",
      "8704/3953\n",
      "8960/3953\n",
      "9216/3953\n",
      "9472/3953\n",
      "9728/3953\n",
      "9984/3953\n",
      "10240/3953\n",
      "10496/3953\n",
      "10752/3953\n",
      "11008/3953\n",
      "11264/3953\n",
      "11520/3953\n",
      "11776/3953\n",
      "12032/3953\n",
      "12288/3953\n",
      "12544/3953\n",
      "12800/3953\n",
      "13056/3953\n",
      "13312/3953\n",
      "13568/3953\n",
      "13824/3953\n",
      "14080/3953\n",
      "14336/3953\n",
      "14592/3953\n",
      "14848/3953\n",
      "15104/3953\n",
      "15360/3953\n",
      "15616/3953\n"
     ]
    }
   ],
   "source": [
    "stereotype_df = pd.read_csv(\"../stereotype_scored.csv\")\n",
    "\n",
    "input_text = stereotype_df[\"sentence\"].tolist()\n",
    "i = 0\n",
    "all_predictions = []\n",
    "for y in data_iterator(train_y=input_text):\n",
    "    print(str(i * 256) + '/' + str(len(input_text)))\n",
    "    i += 1\n",
    "    ids = encode_batch(y, (tokenizer, model))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if torch.cuda.is_available():\n",
    "            input_ids = Tensor(ids).cuda().long()\n",
    "        else:\n",
    "            input_ids = Tensor(ids).long()\n",
    "        outputs = model(input_ids)\n",
    "        y_pred = outputs[0]\n",
    "\n",
    "    predicted = y_pred.cpu().data\n",
    "    all_predictions.extend(predicted.numpy())\n",
    "\n",
    "all_res = np.array(all_predictions).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b2b785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14493437,  0.05288467, -0.02863716, ...,  0.2626121 ,\n",
       "        0.30406514,  0.39996472], shape=(3953,), dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4162bdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generalisation_category_label</th>\n",
       "      <th>connotation</th>\n",
       "      <th>gram_form</th>\n",
       "      <th>generalisation_situation</th>\n",
       "      <th>situation_evaluation</th>\n",
       "      <th>sentence</th>\n",
       "      <th>scsc_score</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>roberta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>generic_generic target</td>\n",
       "      <td>negative</td>\n",
       "      <td>noun</td>\n",
       "      <td>enduring characteristics_abstract</td>\n",
       "      <td>negative</td>\n",
       "      <td>Bangladesh people are lous and quarell they ar...</td>\n",
       "      <td>0.859226</td>\n",
       "      <td>True</td>\n",
       "      <td>0.144934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>individual_specific target</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noun</td>\n",
       "      <td>enduring characteristics_abstract</td>\n",
       "      <td>negative</td>\n",
       "      <td>My friend from bangladesh is very poor.</td>\n",
       "      <td>0.597453</td>\n",
       "      <td>False</td>\n",
       "      <td>0.052885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generic_generic target</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noun</td>\n",
       "      <td>other_not-applicable</td>\n",
       "      <td>not-applicable</td>\n",
       "      <td>Most people in bangladesh are indian</td>\n",
       "      <td>0.747598</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.028637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not-applicable_not-applicable</td>\n",
       "      <td>not-applicable</td>\n",
       "      <td>not-applicable</td>\n",
       "      <td>not-applicable_not-applicable</td>\n",
       "      <td>not-applicable</td>\n",
       "      <td>I think bangladesh is a poor country</td>\n",
       "      <td>0.470234</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subset_specific target</td>\n",
       "      <td>negative</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>enduring characteristics_abstract</td>\n",
       "      <td>negative</td>\n",
       "      <td>They are from bangladesh so they must be stoners.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.161610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>subset_generic target</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noun</td>\n",
       "      <td>enduring characteristics_abstract</td>\n",
       "      <td>negative</td>\n",
       "      <td>African immigrants are gorillas.</td>\n",
       "      <td>0.690731</td>\n",
       "      <td>True</td>\n",
       "      <td>0.323548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>generic_generic target</td>\n",
       "      <td>negative</td>\n",
       "      <td>noun</td>\n",
       "      <td>enduring characteristics_concrete</td>\n",
       "      <td>negative</td>\n",
       "      <td>Immigrants are the worst, they are feral human...</td>\n",
       "      <td>0.790333</td>\n",
       "      <td>True</td>\n",
       "      <td>0.258124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>subset_generic target</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noun</td>\n",
       "      <td>enduring characteristics_concrete</td>\n",
       "      <td>negative</td>\n",
       "      <td>Get all the Pakistanis out of England, they're...</td>\n",
       "      <td>0.687516</td>\n",
       "      <td>True</td>\n",
       "      <td>0.262612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>generic_generic target</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noun</td>\n",
       "      <td>enduring characteristics_concrete</td>\n",
       "      <td>negative</td>\n",
       "      <td>Jewish people are globalist elites orchestrati...</td>\n",
       "      <td>0.744423</td>\n",
       "      <td>True</td>\n",
       "      <td>0.304065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>generic_generic target</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noun</td>\n",
       "      <td>enduring characteristics_concrete</td>\n",
       "      <td>negative</td>\n",
       "      <td>Jewish people are anti-Christian.</td>\n",
       "      <td>0.744423</td>\n",
       "      <td>True</td>\n",
       "      <td>0.399965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3953 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      generalisation_category_label     connotation       gram_form  \\\n",
       "0            generic_generic target        negative            noun   \n",
       "1        individual_specific target         neutral            noun   \n",
       "2            generic_generic target         neutral            noun   \n",
       "3     not-applicable_not-applicable  not-applicable  not-applicable   \n",
       "4            subset_specific target        negative         pronoun   \n",
       "...                             ...             ...             ...   \n",
       "3948          subset_generic target         neutral            noun   \n",
       "3949         generic_generic target        negative            noun   \n",
       "3950          subset_generic target         neutral            noun   \n",
       "3951         generic_generic target         neutral            noun   \n",
       "3952         generic_generic target         neutral            noun   \n",
       "\n",
       "               generalisation_situation situation_evaluation  \\\n",
       "0     enduring characteristics_abstract             negative   \n",
       "1     enduring characteristics_abstract             negative   \n",
       "2                  other_not-applicable       not-applicable   \n",
       "3         not-applicable_not-applicable       not-applicable   \n",
       "4     enduring characteristics_abstract             negative   \n",
       "...                                 ...                  ...   \n",
       "3948  enduring characteristics_abstract             negative   \n",
       "3949  enduring characteristics_concrete             negative   \n",
       "3950  enduring characteristics_concrete             negative   \n",
       "3951  enduring characteristics_concrete             negative   \n",
       "3952  enduring characteristics_concrete             negative   \n",
       "\n",
       "                                               sentence  scsc_score  \\\n",
       "0     Bangladesh people are lous and quarell they ar...    0.859226   \n",
       "1               My friend from bangladesh is very poor.    0.597453   \n",
       "2                  Most people in bangladesh are indian    0.747598   \n",
       "3                  I think bangladesh is a poor country    0.470234   \n",
       "4     They are from bangladesh so they must be stoners.    1.000000   \n",
       "...                                                 ...         ...   \n",
       "3948                   African immigrants are gorillas.    0.690731   \n",
       "3949  Immigrants are the worst, they are feral human...    0.790333   \n",
       "3950  Get all the Pakistanis out of England, they're...    0.687516   \n",
       "3951  Jewish people are globalist elites orchestrati...    0.744423   \n",
       "3952                  Jewish people are anti-Christian.    0.744423   \n",
       "\n",
       "      stereotype  roberta_score  \n",
       "0           True       0.144934  \n",
       "1          False       0.052885  \n",
       "2           True      -0.028637  \n",
       "3          False       0.000372  \n",
       "4           True       0.161610  \n",
       "...          ...            ...  \n",
       "3948        True       0.323548  \n",
       "3949        True       0.258124  \n",
       "3950        True       0.262612  \n",
       "3951        True       0.304065  \n",
       "3952        True       0.399965  \n",
       "\n",
       "[3953 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(\"../stereotype_scored.csv\")\n",
    "\n",
    "results_df['roberta_score'] = all_res\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e44b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['roberta_score'] = (results_df['roberta_score'] - results_df['roberta_score'].min()) / (results_df['roberta_score'].max() - results_df['roberta_score'].min())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850fb71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scsc_score</th>\n",
       "      <th>roberta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3953.000000</td>\n",
       "      <td>3953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.592901</td>\n",
       "      <td>0.656349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.193902</td>\n",
       "      <td>0.211089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.452005</td>\n",
       "      <td>0.517786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.680905</td>\n",
       "      <td>0.700605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.747638</td>\n",
       "      <td>0.832161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        scsc_score  roberta_score\n",
       "count  3953.000000    3953.000000\n",
       "mean      0.592901       0.656349\n",
       "std       0.193902       0.211089\n",
       "min       0.000000       0.000000\n",
       "25%       0.452005       0.517786\n",
       "50%       0.680905       0.700605\n",
       "75%       0.747638       0.832161\n",
       "max       1.000000       1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3fc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = results_df.drop(columns=[x for x in results_df.columns if x not in ['roberta_score', 'sentence', 'scsc_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e436d735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scsc_score</th>\n",
       "      <th>roberta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scsc_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.705033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_score</th>\n",
       "      <td>0.705033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               scsc_score  roberta_score\n",
       "scsc_score       1.000000       0.705033\n",
       "roberta_score    0.705033       1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.drop(columns=['sentence']).corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea6a9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"../stereotype_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
